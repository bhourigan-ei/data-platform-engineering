# DDO Data Platform Github Workflow for Feature Development.yml
name: Feature Development Pipeline

on:
  push:
    branches: [ 'feature/*' ]
  pull_request:
    branches: [ dev ]
    types: [ opened, synchronize, reopened ]

env:
  DBX_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
  DBX_HOST: ${{ secrets.DATABRICKS_HOST }}
  PERSONAL_CLUSTER_ID: ${{ secrets.PERSONAL_CLUSTER_ID }}

jobs:
  code-quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Code Quality Checks
        run: |
          python -m pip install black isort mypy pytest
          black --check .
          isort --check-only .
          mypy src/
          
      - name: Unit Tests
        run: |
          pytest tests/unit --cov=src --cov-report=xml
          
      - name: Upload Coverage
        uses: actions/upload-artifact@v3
        with:
          name: coverage-report
          path: coverage.xml

  workspace-sync:
    needs: code-quality
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Install Databricks CLI
        run: pip install databricks-cli dbx
          
      - name: Sync to Personal Workspace
        run: |
          WORKSPACE_PATH="/Users/${{ github.actor }}/workspace/$(echo $GITHUB_REF_NAME | sed 's/\//_/g')"
          databricks workspace mkdirs $WORKSPACE_PATH
          databricks workspace import_dir ./src $WORKSPACE_PATH --overwrite
          
      - name: Build Development Bundle
        run: |
          dbx bundle validate --file conf/bundle.yml
          dbx bundle deploy \
            --target-env development \
            --files-only \
            --bundle-file conf/bundle.yml \
            --storage-path dbfs:/FileStore/${{ github.actor }}/bundles
